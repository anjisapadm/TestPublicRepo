```mermaid
flowchart TB
    mmflrounded["<span style="padding-left: 8px; padding-right: 8px;">Indicate the study type that resulted in your data (i.e., how the data was obtained).</span><br>"] -- Other study type or non-study data --> n1["<p style="padding: 20px; width: 800px;">Being a participant in the study or a data subject could have affected participants' behavior.</p><p style="">For instance, participants might not tell the truth or omit things. This could be the case when they don't remember, focus on positive result, or give an answer they believe the researcher is looking for.</p>"]
    mmflrounded -- Randomized Controlled Trial --> n2["Data collection was blinded for participants (i.e. study participants did not know which group they had been assigned to)."]
    n2 -- Yes --> n3["Data collection was double-blinded (i.e. study participants and researchers did not know which group study participants had been assigned to)."]
    n1 -- No --> n4["Interviewers or data collectors could give different weight to elements that confirm their beliefs or that disprove them<span style="background-color: rgb(242, 71, 38);">.</span><br>"]
    n5["<p style="padding: 20px; width: 800px;"><span style="padding-left: 8px; padding-right: 8px;">Your dataset may have reporting bias, such as recall or social desirability bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Reporting bias occurs when the frequency of events, properties, or outcomes captured the data does not accurately reflect their real-world frequency. This bias can arise because people tend to focus on documenting circumstances that are unusual or especially memorable (recall bias) or on reporting events or giving answers that they think are desirable (social desirability bias).</span><br></p>"] -- Mitigation --> n6["<p style="padding: 20px; width: 800px;"><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Recall bias can be mitigated by blinding the data collection and by using additional/different assessments than only participant interviews (e.g. supplementing self-report with other-report). Certain factors increase the risk of recall bias, e.g. asking about information from a long time ago, age and education of participants. A prospective design generally decreases the risk of recall bias.</p><p></p><p>Social desirability bias can be reduced by making sure that the participants do not know the purpose of the study and by anonymizing data collection. Other techniques that have been proposed include adapting study protocols to reduce socially desirable responses, e.g. by leaving the room during questionnaire fill-out or by using specialized questioning techniques. In addition, it may be helpful to assess participants for likelihood to respond socially desirably.</p>"]
    n1 -- Yes --> n5
    n2 -- No --> n5
    n6 -.-> n3 & n4
    n4 -- No --> n7["The data collection process was standardized, i.e., consistent and clear methods were used to instruct the collectors and to collect the data."]
    n7 -- yES --> n8["The data is from a study where participants were asked to work with or adhere to an intervention.<br>"]
    n7 -- NO or I DON'T KNOW --> n9["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">interviewer or confirmation bias</span>.</p><p></p><p>Interviewer bias means that the interaction between the researcher and the participants was not standardized. Confirmation bias means that the researcher’s beliefs influenced the way data was collected or labelled.</p>"]
    n3 -- Yes --> n8
    n3 -- No --> n9
    n9 -- Mitigation --> n10["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Interviewer bias can be mitigated with standardised procedures (designed with bias prevention in mind), with proper training for experimenters and by double-blinding.</p><p>The risk of confirmation bias can be reduced by pre-registering the study and/or hypotheses that will be tested. In addition, double-blinding can help prevent confirmation bias.</p>"]
    n4 -- Yes --> n9
    n10 -.-> n8 & n7
    n8 -- yES --> n11["Study participants received clear instructions for adherence to the intervention and/or data on compliance is collected and incorporated into the data analysis."]
    n11 -- Yes --> n12["Participants in the control group may have been exposed to the intervention and/or some participants in the intervention group did not comply with the intervention."]
    n12 -- NO OR N/A --> n13["Data collection was randomized across the relevant groups, i.e. participants were randomly assigned to the groups."]
    n11 -- NO OR I DON'T KNOW --> n14["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">compliance bias</span>.</p><p></p><p>Compliance bias means that interpretation of the main effect is difficult because it is partially determined by differences in the degree of adherence to an intervention.</p>"]
    n14 -- Mitigation --> n15["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Compliance bias can be mitigated by having clear instructions for study participants, by collecting data on compliance, and by incorporating compliance as a confounding factor into the data analysis.</p><p></p><p><em style="color: rgb(45, 155, 240);">After Data Collection:</em></p><p>Intention to treat analysis can be used to mitigate compliance bias. In addition, exploratory data analyses investigating the impact of compliance/non-compliance can help inform to what degree compliance affected the outcome of interest.</p>"]
    n15 -.-> n12
    n8 -- No --> n16["Data size is sufficient for the task and is at least the size of the required sample size. Sample size was determined based on tooling (in case of hypothesis testing) or by careful consideration of model parameters and validation requirements (in case of AI model testing)."]
    n12 -- YES OR I DON'T KNOW --> n17["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">contamination bias</span>.</p><p></p><p>Contamination bias means that activities similar to the intervention affect the behavior in the control condition and lead to an underestimation of the effectiveness of the intervention. Similarly, non-compliance in the intervention condition can lead to contamination bias.</p>"]
    n17 -- Mitigation --> n18["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Contamination bias can be mitigated by having clear instructions for both study participants and clinicians. In addition, other statistical design methods have been proposed to minimize contamination bias, e.g. cluster randomization.</p><p></p><p><em style="color: rgb(45, 155, 240);">After Data Collection:</em></p><p>Exploratory data analyses can help better understand the impact of contamination bias on the outcome of interest. Causal effect estimation techniques can help to adjust for contamination after data collection.</p>"]
    n18 --> n13
    n13 -- YES --> n16
    n13 -- NO OR I DON'T KNOW --> n19["Participants in different groups have been matched (e.g. on age, disease)."]
    n19 -- YES --> n16
    n19 -- NO OR I DON'T KNOW --> n20["<span style="padding-left: 8px; padding-right: 8px;">Your dataset may have channeling bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Channeling bias may occur when participants are assigned to groups by the study leads or staff. As a consequence, there might be imbalances in risk-factors between the groups being compared which could impact the effect of the intervention.</span><br>"]
    n20 -- Mitigation --> n21["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Channeling bias can be mitigated by random sampling. In addition, knowledge of the context is crucial to avoid channeling bias.</p><p></p><p><em style="color: rgb(45, 155, 240);">After Data Collection:</em></p><p>Exploratory data analyses can be useful to assess the potential impact of patient prognostic factors or degree of illness on the outcome of interest. It would be useful to explore to what degree these factors are equally distributed across groups.</p>"]
    n21 -.-> n16
    n16 -- YES --> n22["<span style="padding-left: 8px; padding-right: 8px;">An exploratory analysis of relevant demographics of the target user group was done before data collection and was taken into account when collecting this data.&nbsp;</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">(e.g., when investigating gum health, pregnant women might be relevant because pregnancy affects gum health)</span><br>"]
    n22 -- YES --> n23["<span style="padding-left: 8px; padding-right: 8px;">The included subjects/the data are representative of the target population of your solution.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Note that representativeness depends a lot on your use case and intended user group.&nbsp;</span><span style="padding-left: 8px; padding-right: 8px;">For instance, depending on the variables that are relevant for the study, the sample statistics should be comparable to population statistics, e.g., sex, BMI, age groups, financial status, educational level, ethnicities, home area, number of pregnancies. Furthermore, even when representative for the population in a certain context, a sample can be biased for the intended solution for example in the following ways: very few minorities or people with disabilities included, narrow range of BMI or age groups, insufficient participants of a for the study relevant gender or ethnic group.</span><span style="padding-left: 8px; padding-right: 8px;">.</span><br>"]
    n23 -- YES --> n24["There is considerably more data available for one (sub)group or class over another."]
    n24 -- NO --> n25["<p>There are or are likely to be missing data.</p><p>For instance, there is risk of attrition (drop-out, no-show or otherwise leaving the study) or a risk of non-disclosure (for instance for sensitive questions).&nbsp;</p>"]
    n25 -- NO --> n26["<span style="padding-left: 8px; padding-right: 8px;">Consider for your data and the most important (sub)groups in your data:</span><span style="padding-left: 8px; padding-right: 8px;">There are factors (other than the accounted for independent variables) that could contribute to a change in the variable of interest.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">E.g., income could influence eating patterns, or having taken a course at an earlier stage can influence current test score performance.</span><br>"]
    n25 -- YES OR I DON'T KNOW --> n27["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">selection bias or class imbalance bias.</span></p><p></p><p>Selection bias means that your data sample is not representative for the&nbsp;population of interest. Both may lead to systematic disadvantaging (sub)groups of stakeholders.</p>"]
    n16 -- NO OR I DON'T KNOW --> n27
    n27 -- MITIGATION --> n28["<p class="MsoNormal" style="padding: 20px; width: 800px;"><i>Prior to Data collection:</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>Selection bias can be mitigated by inclusive study design: utilize multiple recruitment channels, collaborate with community organizations, address barriers to participation and make sure that the study materials are inclusively formulated and designed. Create an understanding of the impacted community and engage in early, meaningful and ongoing community consultation.</i></p><p class="MsoNormal" style=""><i>&nbsp;</i></p><p class="MsoNormal" style=""><i>Track detailed demographic information to monitor the representativeness of your sample.&nbsp;</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>Pre-registration of a study increases transparency and allows to evaluate the risk of selection bias beforehand.</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>After Data Collection:</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>Techniques like simple random sampling, systematic sampling, stratified random sampling, and cluster sampling can improve the balance between classes. Two-phase learning and dynamic sampling can mitigate the risk of over- and underfitting. When you resample training data, do not evaluate your model on the resampled data because the model will overfit to that resampled distribution</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>Instead of transforming the training data, the reweighing method attaches weight to each case such that there is statistical parity in the data with respect to the protected feature.&nbsp;</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>It is important to not simply exclude cases with missing values because that may lead to selection (and other) bias(es). For instance, missing data may be more frequent in marginalized populations. because of compounding collection biases, missing and spurious data is often not random. You can use intention-to-treat analysis or imputation.&nbsp;</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>The use of imputation/synthetic data can help to balance classes but be aware that it can result in other biases (e.g., selection or confirmation) bias. It is therefore in all cases crucial to conduct exploratory data analyses to check whether your dataset is representative of the population of interest, and to check whether the characteristics of the synthetic data do not differ significantly from the original data.</i></p><p class="MsoNormal" style=""><i><br></i></p><p class="MsoNormal" style=""><i>Instead of transforming the training data, the reweighing method attaches weight to each case such that there is statistical parity in the data with respect to the protected feature. The same effect can also be achieved by sampling cases.</i></p>"]
    n28 -.-> n22 & n23 & n24 & n25 & n26
    n22 -- NO OR I DON'T KNOW --> n27
    n24 -- YES OR I DON'T KNOW --> n27
    n23 -- NO OR I DON'T KNOW --> n27
    n26 -- NO --> n29["<span style="padding-left: 8px; padding-right: 8px;">Based on the inclusion/exclusion criteria, certain groups were excluded for the study.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Consider groups of a certain sex or gender, racial and ethnic minorities, socio-economic status, elderly and pediatric populations, and pregnant women.</span><br>"]
    n26 -- YES OR I DON'T KNOW --> n30["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">confounding bias</span>.</p><p></p><p>Confounding bias means that variables outside the scope of the existing model were not controlled for but these variables influence both the independent and dependent variables.</p>"]
    n30 -- Mitigation --> n31["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>This can be mitigated by including known confounders in the study design. Unknown confounders can be partially controlled for with randomisation and having a large sample size. Also, using directed acyclic graphs can help to identify causal effects between variables.</p><p></p><p><em style="color: rgb(45, 155, 240);">After Data Collection:</em></p><p>Causal effect estimation techniques can help to remove confounding bias from data. For instance, using propensity scores (people with higher scores are more likely to have certain confounders, these scores are used to build a statistical model) can mitigate confounding. Directed acyclic graphs can help identify those variablles that need to be controlled for in your statistic analyses.</p>"]
    n29 -- NO OR N/A --> n32["<span style="padding-left: 8px; padding-right: 8px;">The impact of unique anatomical, physiological, and identity characteristics of subjects on the outcome of interest was considered.&nbsp;</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">(E.g., different genetic or physiological factors influence drug metabolism or intervention efficacy.)</span><br>"]
    n29 -- YES OR I DON'T KNOW --> n33["This data might be used (now or in the future) to draw conclusions or create solutions that could impact the excluded groups.&nbsp;<br>"]
    n31 -.-> n29
    n33 -- NO OR N/A --> n32
    n32 -- YES OR N/A --> n34["There are labels for sex and/or gender of subjects/participants."]
    n32 -- NO OR I DON'T KNOW --> n35["<span style="padding-left: 8px; padding-right: 8px;">Your dataset may have homogeneity bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Homogeneity bias is the assumption that members of a group are similar without accounting for individual differences. It overlooks the diversity within a group, treating it as a uniform entity.&nbsp;</span><br>"]
    n33 -- YES OR I DON'T KNOW --> n36["<span style="padding-left: 8px; padding-right: 8px;">Your dataset may have exclusion bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Exclusion bias is a systematic exclusion of certain subgroups or not properly understanding the impact of the solution, leading to complete or skewed understanding of the solution's impact.</span><br>"]
    n36 -- Mitigation --> n37["<span style="padding-left: 8px; padding-right: 8px;">Prior to Data collection:</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Consider how different subgroups might be uniquely affected. Involve community members or representatives of the groups early in the process, ensuring their perspectives and needs are addressed. Consider alternative methods to include data from sensitive groups, like survey or interview studies. You might use existing data from previous studies to include sensitive populations and (hypothesize about) relevant outcomes. The design of the study could also be adapted for a seperate cohort study with additional safety measures that does include these groups.&nbsp;</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">After Data Collection:</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Clearly document and justify reasons for exclusion.&nbsp;</span><span style="padding-left: 8px; padding-right: 8px;">Be transparent about the study or datasets limitations and any potential biases (e.g., document this in the Data Catalog). Do not generalize conclusions.&nbsp;</span><span style="padding-left: 8px; padding-right: 8px;">Set up proper market surveillance to monitor the effects on the (excluded or sensitive) groups in real-world settings. Set up reporting systems for sensitive groups to use if the system does not meet their requirements.&nbsp;</span><br>"]
    n35 -- Mitigation --> n37
    n37 -.-> n32 & n34
    n34 -- NO OR N/A --> n38["Data annotation is part of the data collection process."]
    n38 -- NO --> n44["A measure of classification agreement between the data collectors (e.g. interrater reliability) is used to align on the outcome measures and/or labels."]
    n44 -- YES or N/A --> n45["<p style="">In case of groups: the same measures have been used across different participants or groups.</p><p style="">E.g., in case of recordings, the same recording device was used for all participants.</p>"]
    n45 -- YES or N/A --> n46["<p style="">Valid and reliable outcome measures have been used for collecting the data.</p><p style="">E.g, clear considerations for using categorical/ordinal/cardinal scales, use of state of the art measurement scales and devices.</p>"]
    n46 -- YES --> n47["Direct measures for the outcome variables of interest rather than proxy measures have been used.<br>"]
    n46 -- NO --> n55["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">measurement bias</span>.</p><p></p><p>Measurement bias means that the measures used in the study to assess the particpant (e.g. self-report measures or clinical measures) are not appropriate for the study population or setting, or are indirect measures of the outcome of interest.</p>"]
    n34 -- YES or I DON'T KNOW --> n49["Untitled Node"]
    n49 -- YES --> n38
    n38 -- YES --> n50["Labels are﻿ clearly defined (e.g. unambiguous) and are tested for stereotypes.&nbsp;<br>"]
    n50 -- YES --> n51["The labels are assigned by experts who receive clear instructions and training, and/or are knowledgeable in the domain.&nbsp;<br>"]
    n51 -- YES --> n44
    n50 -- NO or I DON'T KNOW --> n52["<span style="padding-left: 8px; padding-right: 8px;">Your dataset may have labeling bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Labeling bias means that labels are differently assigned to groups of people based on stereotypes in our society.</span><br>"]
    n52 -- Mitigation --> n53["<span style="padding-left: 8px; padding-right: 8px;">Prior to Data collection:<br></span><span style="padding-left: 8px; padding-right: 8px;">Use multiple human annotators per data point (ideally with expertise in the domain) who label data independently, and make sure that they have high interrater reliability.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">After Data Collection:<br></span><span style="padding-left: 8px; padding-right: 8px;">In case of multiple human annotators, those data points for which the labels disagree a lot can be removed from the data. In case of automated labelling, we can use semi-supervised labelling: we infer a probability that the unlabelled examples are correctly classified and feed that back into the classifier with a weight that is proportional to that probability. Alternatively, a bias correction framework can be used, where the biased dataset is re-weighted to fit the (theoretical) unbiased dataset, and only then fed into a machine learning algorithm as training data.</span><br>"]
    n53 -.-> n51 & n44
    n44 -- NO OR I DON'T KNOW --> n54["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">misclassification bias</span>.</p><p></p><p>Misclassification bias means that participants have been incorrectly assigned to a category, altering the outcome of interest.</p>"]
    n45 -- NO --> n54 & n55
    n47 -- NO --> n55
    n54 -- Mitigation --> n56["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Misclassification bias can be mitigated by standardising data collection and using reliable and valid measures. In addition, prospective study designs reduce the risk of misclassification bias. Since there is always a risk that some participants are misclassified, a large enough sample size is important.</p><p></p><p><em style="color: rgb(45, 155, 240);">After Data Collection:</em></p><p>Bootstrap imputation can be used to reduce misclassification bias. In addition, quantitative bias analysis has been proposed to account for misclassification bias.</p>"]
    n56 -.-> n45 & n46
    n55 --> n57["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Measurement bias can be prevented by selecting measures that are appropriate for the study population and setting as well as by using measures that have been shown to be valid and reliable. It can be helpful to report the validity and reliability of the measures used.</p><p></p><p>Try to avoid using proxies for outcomes but instead use direct measures if possible. In addition, since measures that have low sensitivity may not detect the outcome of interest, it is also important to have information about the sensitivity of a measure.</p>"]
    n57 -.-> n47
    n47 -- YES --> n58["<span style="padding-left: 8px; padding-right: 8px;">The way that participants have been included (or have been asked consent), or the way that data is obtained (e.g. by social media, from a particular site, by opt-in) could result in a misrepresentation of the target population.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">For example, a large number of people invited to participate disagreed to participate in the study, or some people had limited access to the system/site, or&nbsp; data covers mostly most popular items or most active persons, or people with specific factors that may affect the outcome of interest have been included in the study.</span><br>"]
    n57 --> n58
    n58 -- YES --> n59["<span style="padding-left: 8px; padding-right: 8px;">Your dataset may have participation bias or (self-)selection bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Participation bias means that the included subjects do not properly represent the target population or disproportionately possess certain traits which affect the outcome (e.g., being more motivated or more active). Self-selection bias results when subjects self-select for enrollment and may be healthier or more motivated than the general public.​</span><br>"]
    n58 -- NO --> n62["Data for different participants or groups has been collected at time points that are far apart (e.g. years), or at an earlier time where there was a significant difference in way of working (e.g. before a hospital started working with a new scanner or there was a change in disease definitions).<br>"]
    n59 -- Mitigation --> n61["<span style="padding-left: 8px; padding-right: 8px;">Prior to Data collection:</span><span style="padding-left: 8px; padding-right: 8px;">Participation bias can be mitigated by including participants via different means (e.g. phone, mail, in-person etc.) and by including participants regardless of whether or not all data is available. Additional data collection or using additional data sources may be necessary. Ensuring anonymity and confidentiality can help increase participation and decrease participation bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">After Data Collection</span><span style="padding-left: 8px; padding-right: 8px;">In case the variable associated with the bias was recorded (e.g. character trait or health) then this can be adjusted by using stratification or propensity score. If not, weighing, sensitivity analysis or even data imputation could help mitigate the bias. The use of additional data sources is also a way to improve representativeness.&nbsp;</span><br>"]
    n61 -.-> n62
    n62 -- NO --> n63["The outcome of interest is a diagnostic test."]
    n62 -- YES --> n64["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">historical/chronology bias</span>.</p><p></p><p>Historical/chronology bias means that part of your dataset was collected at a different time point when things were potentially done differently. As a consequence, the different subsamples are not comparable.</p>"]
    n64 -- Mitigation --> n65["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>Historical data/chronology bias can be mitigated by using a prospective study design and by not using historical controls. In addition, in a randomised controlled trial (RCT), using small block sizes for randomisation can reduce chronology bias.</p><p></p><p><em style="color: rgb(45, 155, 240);">After Data Collection:</em></p><p>If it is known that there is a historical bias in a sample, a way to mitigate this is by using different approval thresholds for different groups in the sample (e.g. salary for women and men).</p>"]
    n65 -.-> n63
    n63 -- NO --> n66["The study involved a follow-up in which it was studied how effects changed/persisted over time."]
    n63 -- YES --> n67["The dataset consists of individuals that represent the population in which the diagnostic test will be typically used."]
    n66 -- NO --> n68["The study involved a follow-up in which it was studied how effects changed/persisted over time."]
    n67 -- YES --> n68
    n67 -- NO --> n69["<p>Your dataset may have <span style="color: rgb(218, 0, 99);">spectrum bias</span>.</p><p></p><p>Spectrum bias means that there is variability of diagnostic test performance because of differences in severity of the disease. This means that the performance of a diagnostic test may be different in a different sample.</p>"]
    n69 -- Mitigation --> n70["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p>It is important that the study in which the diagnostic accuracy of a test is assessed includes individuals who are representative of the population in which the test will typically be used.</p><p></p><p><em style="color: rgb(45, 155, 240);">After data collection:</em></p><p>Exploratory analyses can be helpful to assess differences in diagnostic test performance in different subgroups.</p><p>Information about the possibility of a spectrum bias should be provided so that clinicians who use a diagnostic test know that its performance may be different depending on the characteristics of the patient.</p>"]
    n70 -.-> n68
    n68 -- NO OR I DON'T KNOW --> n71["<span style="background-color: transparent;">END OF &nbsp;DATA COLLECTION</span><br>"]
    n68 -- YES --> n72["A significant amount of (participant) data was lost at follow-up AND/OR study groups have unequal issues at follow-up.<br>"]
    n72 -- NO --> n71
    n72 -- YES --> n73["<span style="padding-left: 8px; padding-right: 8px;">Your dataset may have follow-up bias.</span><span style="padding-left: 8px; padding-right: 8px;"><br></span><span style="padding-left: 8px; padding-right: 8px;">Transfer bias means that participants are lost at follow-up or that only the participants with a certain outcome are included, e.g. because one of the interventions is more effective or because a risk factor is more likely in one group.</span><br>"]
    n73 -- Mitigation --> n74["<p><em style="color: rgb(45, 155, 240);">Prior to Data collection:</em></p><p><span style="color: rgb(26, 26, 26);">This bias can be prevented by ensuring good communication between researchers and participants and by providing incentives to continue. In addition, it is important to have a plan for handling of missing data in place prior to the data collection and to pre-register this analysis plan.</span></p><p></p><p><em style="color: rgb(45, 155, 240);">After data collection:</em></p><p>It is necessary to analyze whether attrition is higher in some of the groups. It is important to carefully consider reasons for attrition and to use analysis methods such as intention to treat analysis.</p>"]
    n74 -.-> n71




